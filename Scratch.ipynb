{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0af97641-b9ba-4eb2-9752-5625e5f02160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from torchvision import datasets,transforms\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm \n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2648c3b3-32ee-4ff9-a0c1-58a0850edd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root=\"../data\", download = True,train = True, transform = transforms.ToTensor())\n",
    "test = datasets.MNIST(root=\"../data\", download = True,train = False, transform = transforms.ToTensor())\n",
    "train = Subset(train, list(range(320)))\n",
    "# len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "904990f4-7255-4e66-a69f-add4266c5a3c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __intit__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self,input):\n",
    "        self.last_input = input\n",
    "        exp_x = np.exp(input - np.max(input))\n",
    "        # print(\"SOFTMAX:-\",exp_x/np.sum(exp_x, axis = 0, keepdims = True) )\n",
    "        return exp_x/np.sum(exp_x, axis = 0, keepdims = True)\n",
    "\n",
    "    def backward(self,loss):\n",
    "        for i, grad in enumerate(loss):\n",
    "            if grad == 0:\n",
    "                continue\n",
    "            exp = np.exp(self.last_input)\n",
    "            sum_exp = np.sum(exp)\n",
    "\n",
    "            out = -exp[i]*exp/(sum_exp**2)\n",
    "            out[i] = exp[i]*(sum_exp-exp[i])/(sum_exp**2)\n",
    "            out = out*grad\n",
    "        return out\n",
    "\n",
    "class Linear():\n",
    "    def __init__(self,input_size,output_size):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.weights = np.random.rand(input_size, output_size) - 0.5\n",
    "        self.bias = np.random.rand(self.output_size) - 0.5\n",
    "    def forward(self,input):\n",
    "        self.last_input = input \n",
    "        # print(self.weights)\n",
    "        return np.dot(input, self.weights) + self.bias\n",
    "    def backward(self,loss, learning_rate):\n",
    "        # print(loss, self.last_input,self.weights)\n",
    "        dt_dw = self.last_input\n",
    "        dt_db = 1\n",
    "        dt_dinputs = self.weights\n",
    "        # print(\"*****\",dt_dinputs.shape,loss.shape)\n",
    "        dl_dw = dt_dw[np.newaxis].T*loss\n",
    "        dl_db = loss*dt_db\n",
    "        dl_dinputs = dt_dinputs.dot(loss)\n",
    "\n",
    "        # print(dl_dinputs.shape)\n",
    "        \n",
    "        self.weights += learning_rate*dl_dw\n",
    "        self.bias += learning_rate*dl_db\n",
    "\n",
    "        # print('weights',self.weights)\n",
    "\n",
    "        return dl_dinputs.reshape(self.last_input.shape)\n",
    "\n",
    "class MaxPool():\n",
    "    def __init__(self,Kernel_shape , stride):\n",
    "        self.kernel_shape = Kernel_shape\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self,input):\n",
    "        self.last_input = input\n",
    "        num_filters,h,w = input.shape\n",
    "        # print(h,w)\n",
    "        output_shape = (h-self.kernel_shape)//self.stride + 1\n",
    "        output = np.zeros((num_filters,output_shape,output_shape))\n",
    "        # print(output.shape)\n",
    "        for num in range(num_filters):\n",
    "            for i in range(0,h,self.stride):\n",
    "                for j in range(0,w,self.stride):\n",
    "                    \n",
    "                    output[num,i//self.stride,j//self.stride] = np.max(input[num,i:i+self.kernel_shape,j:j+self.kernel_shape])\n",
    "                    # print(output)\n",
    "    \n",
    "        return output\n",
    "\n",
    "    def backward(self,loss):\n",
    "        channels, h, w = loss.shape\n",
    "        \n",
    "        output = np.zeros(self.last_input.shape)\n",
    "        # temp = []\n",
    "        # print(loss.shape)\n",
    "        for num in range(self.last_input.shape[0]):\n",
    "            for i in range(0,self.last_input.shape[1],self.stride):\n",
    "                for j in range(0,self.last_input.shape[2],self.stride):\n",
    "                    # print(num,i,j)\n",
    "                    temp = self.last_input[num,i:i+self.kernel_shape,j:j+self.kernel_shape]\n",
    "                    max = np.amax(temp)\n",
    "                    for i1 in range(temp.shape[0]):\n",
    "                        for j1 in range(temp.shape[1]):\n",
    "                            if temp[i1,j1] == max :\n",
    "                                output[num,i+i1,j+j1] = loss[num, i//self.stride, j//self.stride]\n",
    "\n",
    "        return output\n",
    "\n",
    "class Conv:\n",
    "    def __init__(self,input_channels ,output_channels,kernel_shape = 3, stride = 1, padding = False):\n",
    "        self.output_channels = output_channels\n",
    "        self.kernel_shape = kernel_shape\n",
    "        self.stride = stride\n",
    "        self.padding = padding \n",
    "        self.input_channels = input_channels\n",
    "        limit = np.sqrt(6.0 / (input_channels*kernel_shape**2 + output_channels*kernel_shape**2))\n",
    "        # self.weight = np.random.uniform(-limit, limit, (self.output_channels,self.input_channels,self.kernel_shape,self.kernel_shape))\n",
    "        self.weight = np.random.rand(self.output_channels,self.input_channels,self.kernel_shape,self.kernel_shape) - 0.5\n",
    "        # self.weight = np.array([[[[0,2],[1,1]]]],dtype = np.float64)\n",
    "        # print('weight', self.weight)\n",
    "        self.bias = np.random.rand(self.output_channels) - 0.5\n",
    "        # self.weight = np.array([[[0.1,-0.2],[0.3,+0.6]],[[0.3,0.4],[-0.5,0.1]],[[-0.7,0.8],[0.9,-0.5]]], dtype = np.float64)\n",
    "        \n",
    "        # print(weight)\n",
    "    def forward(self,input):\n",
    "        self.last_input = input\n",
    "        channels,h,w = input.shape\n",
    "        # print(h,self.kernel_shape,self.)\n",
    "        self.output_shape = (h - self.kernel_shape + 2*self.padding)//self.stride + 1\n",
    "        output = np.zeros((self.output_channels, self.output_shape,self.output_shape))\n",
    "        # print(output.shape)\n",
    "        for num in range(self.output_channels):\n",
    "            for i in range(0, h-self.kernel_shape+1, self.stride):\n",
    "                for j in range(0,w-self.kernel_shape+1, self.stride):\n",
    "                    # print(num)\n",
    "                    output[num,i//self.stride,j//self.stride] =  np.sum(input[:,i:i+self.kernel_shape,j:j+self.kernel_shape]*self.weight[num]) +  self.bias[num]\n",
    "                    # print('ooo', self.weight[num])\n",
    "        # print('output_forward', output)\n",
    "        return output\n",
    "    def backward(self, loss, learn_rate):\n",
    "        channels, h, w = self.last_input.shape\n",
    "        dl_dfilters = np.zeros(self.weight.shape)\n",
    "        dl_dinputs = np.zeros(self.last_input.shape)\n",
    "        # dl_dbias = np.zeros(self.bias.shape)\n",
    "        # print(self.weight.shape)\n",
    "        for num in range(self.output_channels):\n",
    "            for i in range(0,h-self.kernel_shape+1, self.stride):\n",
    "                for j in range(0,w-self.kernel_shape+1, self.stride):\n",
    "                    # print(\"****\",loss[num,i//self.stride,j//self.stride].shape,self.last_input[:,i:i+self.kernel_shape,j:j+self.kernel_shape].shape)\n",
    "                    # print(dl_dfilters[num].shape)\n",
    "                    dl_dinputs[:,i:i+self.kernel_shape,j:j+self.kernel_shape] += loss[num,i//self.stride,j//self.stride]*self.weight[num]  \n",
    "                    dl_dfilters[num] += loss[num,i//self.stride,j//self.stride]*self.last_input[:,i:i+self.kernel_shape,j:j+self.kernel_shape]\n",
    "                    # dl_dbias = \n",
    "                    # print('kjdsgfk',num,(loss[num,i//self.stride,j//self.stride]).shape)\n",
    "        # for i in range():\n",
    "        #     dl_dfilters[num] = \n",
    "        # output = np.zeros(self.last_input.shape)\n",
    "        # for num in range(self.output_shape):\n",
    "        #     for i in range(output.shape[1]):\n",
    "        #         for j in range(output.shape[2]):\n",
    "                    \n",
    "        \n",
    "        self.weight += learn_rate*dl_dfilters\n",
    "        # print('Updated weights',self.weight)\n",
    "        # print(self.bias.shape, loss.shape)\n",
    "        self.bias += learn_rate*np.sum(loss, axis = (1,2))\n",
    "        # print(self.weight)\n",
    "        return dl_dinputs\n",
    "\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self,input):\n",
    "        self.last_input = input\n",
    "        return np.maximum(0,input)\n",
    "    def backward(self, loss):\n",
    "        return loss*(self.last_input>0)\n",
    "        \n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self,input):\n",
    "        # channels, h, w = input\n",
    "        self.last_input = input\n",
    "        exp = np.exp(-1*input)\n",
    "        self.output = 1/(1+exp)\n",
    "        # print(self.output)\n",
    "        return self.output\n",
    "        \n",
    "\n",
    "    def backward(self,loss):\n",
    "        # sig = 1/(1+np.exp(-1*self.last_input))\n",
    "        # sig = \n",
    "        out = loss*self.output*(1-self.output)\n",
    "        # print(\"OUT\",out)\n",
    "        return out\n",
    "\n",
    "class Dropout:\n",
    "    def __init__(self,keep_prob):\n",
    "        self.keep_prob = keep_prob\n",
    "    def forward(self,input):\n",
    "        # self.mask = np.random.rand(*input.shape) < keep_prob\n",
    "        # input_shape = i\n",
    "        # self.mask = np.random.choice([0, 1], size=input.shape, p=[1 - self.keep_prob, self.keep_prob])\n",
    "        self.mask = np.random.binomial(1, self.keep_prob, size=input.shape)\n",
    "        input *= self.mask\n",
    "        return input\n",
    "    def backward(self,loss):\n",
    "        return self.mask*loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e181553a-2c34-4b3d-9946-48a784e92f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d862c458-d559-46f5-b923-ef4ff02e655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Linear(10,10)\n",
    "# softmax = Softmax()\n",
    "# conv_2 = Conv(1,1,2)\n",
    "# conv_1 = Conv(1,1,2)\n",
    "# r1 = ReLU()\n",
    "# r2 = ReLU()\n",
    "# l = Linear(5,5)\n",
    "input = np.array([1,4,3,2,5,6,4,7,9,2],dtype = np.float64)\n",
    "# input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "327cdad8-85c1-4e8f-9168-5840698ba361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 23.065650095889072\n",
      "loss 17.483762772683917\n",
      "loss 13.25269218169441\n",
      "loss 10.045540673724362\n",
      "loss 7.614519830683067\n",
      "loss 5.771806031657763\n",
      "loss 4.375028971996587\n",
      "loss 3.3162719607734106\n",
      "loss 2.513734146266246\n",
      "loss 1.9054104828698164\n",
      "loss 1.4443011460153181\n",
      "loss 1.0947802686796126\n",
      "loss 0.8298434436591441\n",
      "loss 0.6290213302936332\n",
      "loss 0.4767981683625736\n",
      "loss 0.3614130116188308\n",
      "loss 0.27395106280707315\n",
      "loss 0.20765490560775982\n",
      "loss 0.15740241845068417\n",
      "loss 0.11931103318561735\n",
      "loss 0.09043776315469688\n",
      "loss 0.06855182447126207\n",
      "loss 0.051962282949215025\n",
      "loss 0.039387410475506104\n",
      "loss 0.0298556571404343\n",
      "loss 0.02263058811244988\n",
      "loss 0.017153985789235483\n",
      "loss 0.013002721228242642\n",
      "loss 0.009856062691006228\n",
      "loss 0.007470895519780895\n",
      "loss 0.005662938803995221\n",
      "loss 0.004292507613427743\n",
      "loss 0.0032537207709798953\n",
      "loss 0.0024663203444019064\n",
      "loss 0.0018694708210570954\n",
      "loss 0.001417058882360278\n",
      "loss 0.001074130632832404\n",
      "loss 0.0008141910196842739\n",
      "loss 0.0006171567929210808\n",
      "loss 0.0004678048490346032\n",
      "loss 0.0003545960755669042\n",
      "loss 0.000268783825280261\n",
      "loss 0.0002037381395633586\n",
      "loss 0.00015443350978893154\n",
      "loss 0.00011706060042075972\n",
      "loss 8.873193511635958e-05\n",
      "loss 6.725880681885954e-05\n",
      "loss 5.09821755680262e-05\n",
      "loss 3.864448908128537e-05\n",
      "loss 2.9292522722812463e-05\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    x = l.forward(input)\n",
    "    loss = np.square(input) - x\n",
    "    print('loss',np.sum(loss)/len(loss))\n",
    "    grad = l.backward(loss,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef7aca08-2ff1-4783-b626-a8a1a6e13de6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "conv1 = Conv(1,32,3)\n",
    "relu1 = ReLU()\n",
    "conv2 = Conv(32,64,3)\n",
    "relu2 = ReLU()\n",
    "pool1 = MaxPool(3,3)\n",
    "drop1 = Dropout(0.5)\n",
    "linear1 = Linear(4096,250)\n",
    "sigmoid1 = Sigmoid()\n",
    "relu3 = ReLU()\n",
    "linear2 = Linear(250,10)\n",
    "softmax1 = Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7cbb2-dc53-44a3-8fc3-53491669ea05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "lr = 0.01\n",
    "\n",
    "# Initialize lists to store losses and accuracies\n",
    "epoch_losses = []\n",
    "epoch_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    correct_count = 0\n",
    "    total_samples = 0\n",
    "    # progress_bar = tqdm(train, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
    "    progress_bar = train\n",
    "    for image, label in progress_bar:\n",
    "        input = np.array(image, dtype=np.float64).reshape(1, 28, 28) - 0.5\n",
    "\n",
    "        # Forward pass\n",
    "        x = relu1.forward(conv1.forward(input))\n",
    "        x = relu2.forward(conv2.forward(x))\n",
    "        x = pool1.forward(x)\n",
    "        x = drop1.forward(x)\n",
    "        print(\"before linear\", x.reshape(-1))\n",
    "        x = relu3.forward(linear1.forward(x.reshape(-1)))\n",
    "        print(\"after linear1\", x)\n",
    "        x = softmax1.forward(linear2.forward(x))\n",
    "        \n",
    "        # loss = -np.log(x[label])\n",
    "        x = np.clip(x, 1e-15, 1 - 1e-15)  \n",
    "        y_true = np.zeros(10)\n",
    "        y_true[label] = 1\n",
    "        # print(x, label, np.argmax(x), 'trueee',y_true)\n",
    "        # loss = -np.sum(y_true * np.log(y_pred))\n",
    "        # epoch_loss += loss\n",
    "\n",
    "        # Calculate accuracy\n",
    "        # prediction = np.argmax(x)\n",
    "        # # print('softmax',/ x, prediction)\n",
    "        # correct_count += 1 if prediction == label else 0\n",
    "        # total_samples += 1\n",
    "\n",
    "        # Compute gradient\n",
    "        grad = np.zeros(10)\n",
    "        # print(prediction,label\n",
    "        grad[label] = -1/x[label]\n",
    "        # grad[label] = 1\n",
    "        # grad = y_true - x\n",
    "\n",
    "        grad = softmax1.backward(grad)\n",
    "        grad = linear2.backward(grad, lr)\n",
    "        grad = relu3.backward(grad)\n",
    "        grad = linear1.backward(grad, lr)\n",
    "        grad = drop1.backward(grad.reshape(64, 8, 8))\n",
    "        grad = pool1.backward(grad)\n",
    "        grad = relu2.backward(grad)\n",
    "        # grad = pool2.backward(grad)\n",
    "        grad = conv2.backward(grad, lr)\n",
    "        grad = relu1.backward(grad)\n",
    "        # grad = pool1.backward(grad)\n",
    "        grad = conv1.backward(grad, lr)\n",
    "\n",
    "        if total_samples == 3200:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    epoch_loss /= len(train)\n",
    "    epoch_accuracy = correct_count / total_samples\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    epoch_accuracies.append(epoch_accuracy)\n",
    "\n",
    "    progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc86fbff-76a8-4bc2-83e4-59ef49d25cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "total_samples = len(test)\n",
    "\n",
    "# Progress bar setup\n",
    "progress_bar = tqdm(test, desc='Evaluating', leave=False)\n",
    "\n",
    "for image, label in progress_bar:\n",
    "    input = np.array(image, dtype=np.float64).reshape(1, 28, 28) \n",
    "\n",
    "    # Forward pass\n",
    "    x = relu1.forward(conv1.forward(input)*0.1)\n",
    "    x = relu2.forward(conv2.forward(x)*0.1)\n",
    "    x = pool1.forward(x)\n",
    "    # x = drop1.forward(x)\n",
    "    x = sigmoid1.forward(linear1.forward(x.reshape(-1)))\n",
    "    x = softmax1.forward(linear2.forward(x))\n",
    "\n",
    "    # Calculate accuracy\n",
    "    prediction = np.argmax(x)\n",
    "    print(prediction)\n",
    "    correct_count += 1 if prediction == label else 0\n",
    "\n",
    "    # Update progress bar with current accuracy\n",
    "    progress_bar.set_postfix(accuracy=f'{correct_count / total_samples:.4f}')\n",
    "\n",
    "# Close progress bar\n",
    "progress_bar.close()\n",
    "\n",
    "# Calculate and print overall accuracy\n",
    "accuracy = correct_count / total_samples\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34120aa9-5017-4ae3-b05d-ea3b925f09bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d298662d-145a-47b6-9ae6-85eac14211b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7932bc3-2898-4ee4-90b7-97a6a89f795a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
